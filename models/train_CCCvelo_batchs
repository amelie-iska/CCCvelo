import torch
import time
import numpy as np
import scanpy as sc
import random
import warnings
from collections import OrderedDict
from scipy.spatial import distance_matrix
# CUDA support
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    device = torch.device('cpu')
warnings.filterwarnings("ignore")

from torch.utils.data import DataLoader, TensorDataset

def create_dataloader(data, batch_size):
    dataset = TensorDataset(*data)  # Assuming data is a tuple (TGs_expr, TFs_expr, TFLR_allscore)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=False)
    return dataloader

# +++++++++++++++++++++++++++++++++++++ the deep neural network ++++++++++++++++++++++++++++++++++++++++
class DNN(torch.nn.Module):
    def __init__(self, layers):
        super(DNN, self).__init__()

        # parameters
        self.depth = len(layers) - 1

        # set up layer order dict
        self.activation = torch.nn.Tanh

        layer_list = list()
        for i in range(self.depth - 1):
            layer_list.append(
                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i + 1]))
            )
            layer_list.append(('activation_%d' % i, self.activation()))

        layer_list.append(
            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))
        )
        layerDict = OrderedDict(layer_list)

        # deploy layers
        self.layers = torch.nn.Sequential(layerDict)

    def forward(self, x):
        out = self.layers(x)
        return out

class SpatialVelocity():
    def __init__(self, TGs_expr, TFs_expr, TFLR_allscore, TGTF_regulate, iroot, layers, lr, Lambda, batch_size):
        # data
        self.TGs_expr = TGs_expr.clone().detach().float().to(device)
        self.TFs_expr = TFs_expr.clone().detach().float().to(device)
        self.TFLR_allscore = TFLR_allscore.clone().detach().float().to(device)
        self.regulate = TGTF_regulate.clone().detach().to(device)
        self.iroot = iroot.int().to(device)
        self.t = torch.linspace(0, 1, 2000).unsqueeze(1).requires_grad_(True).to(device)
        self.Lambda = Lambda
        self.N_cell = TGs_expr.shape[0]
        self.N_TFs = TFs_expr.shape[1]
        self.N_TGs = TGs_expr.shape[1]
        self.N_LRs = TFLR_allscore.shape[2]
        self.batch_size = batch_size

        self.rootcell_exp = self.TGs_expr[self.iroot, :]

        self.V1 = torch.empty((self.N_TFs, self.N_LRs), dtype=torch.float32).uniform_(0, 1).float().requires_grad_(True).to(device)
        self.K1 = torch.empty((self.N_TFs, self.N_LRs), dtype=torch.float32).uniform_(0, 1).float().requires_grad_(True).to(device)
        self.V2 = torch.empty((self.N_TGs, self.N_TFs), dtype=torch.float32).uniform_(0, 1).float().requires_grad_(True).to(device)
        self.K2 = torch.empty((self.N_TGs, self.N_TFs), dtype=torch.float32).uniform_(0, 1).float().requires_grad_(True).to(device)
        self.beta = torch.empty((self.N_TFs),dtype=torch.float32).uniform_(0, 1).float().requires_grad_(True).to(device)
        self.gamma = torch.empty((self.N_TGs),dtype=torch.float32).uniform_(0, 1).float().requires_grad_(True).to(device)

        self.V1 = torch.nn.Parameter(self.V1)
        self.K1 = torch.nn.Parameter(self.K1)
        self.V2 = torch.nn.Parameter(self.V2)
        self.K2 = torch.nn.Parameter(self.K2)
        self.beta = torch.nn.Parameter(self.beta)
        self.gamma = torch.nn.Parameter(self.gamma)

        # DNN model
        self.dnn = DNN(layers).to(device)
        self.dnn.register_parameter('V1', self.V1)
        self.dnn.register_parameter('K1', self.K1)
        self.dnn.register_parameter('V2', self.V2)
        self.dnn.register_parameter('K2', self.K2)

        self.optimizer_Adam = torch.optim.Adam(self.dnn.parameters(), lr=lr)

        # Create DataLoader
        data = (TGs_expr, TFs_expr, TFLR_allscore)
        self.dataloader = create_dataloader(data, batch_size)

    def net_z(self):
        t = self.t
        N_TGs = self.N_TGs
        z0 = self.rootcell_exp.repeat(t.size(0), 1)
        z_and_t = torch.cat([z0, t], dim=1)
        z_dnn = self.dnn(z_and_t)  

        for i in range(N_TGs):
            z_t_pre = torch.autograd.grad(
                z_dnn[:, i], t,
                grad_outputs=torch.ones_like(z_dnn[:, i]),
                retain_graph=True,
                create_graph=True
            )[0]
            if i == 0:
                dz_dt = z_t_pre
            else:
                dz_dt = torch.cat((dz_dt, z_t_pre), 1)
        z_dnn = torch.where(z_dnn > 0, z_dnn, torch.full_like(z_dnn, 0))

        return z_dnn, dz_dt

    def assign_latenttime(self,TGs_expr):
        tpoints = self.t
        z_dnn = self.net_z()[0]
        z_obs = TGs_expr
        # loss_cell_to_t0 = torch.sum((z_dnn.unsqueeze(1) - z_obs.unsqueeze(0)) ** 2, dim=2)  # torch.Size([2000, 2515])

        chunk_size = 500  
        loss_cell_to_t = []

        for i in range(0, z_dnn.size(0), chunk_size):
            z_dnn_chunk = z_dnn[i:i + chunk_size]  # 分块操作
            chunk_loss = torch.sum((z_dnn_chunk.unsqueeze(1) - z_obs.unsqueeze(0)) ** 2, dim=2)
            loss_cell_to_t.append(chunk_loss)

        # 拼接计算结果
        loss_cell_to_t = torch.cat(loss_cell_to_t, dim=0)

        pos = torch.argmin(loss_cell_to_t, dim=0)
        fit_t = tpoints[pos]
        fit_t = fit_t.flatten()[:, None].squeeze()
        # print('the minial loss position of cells is:', pos[1450:1500])
        # print('the shape of loss_cell_to_t is:', loss_cell_to_t.shape) # torch.Size([2000, 2515])
        # print('the fit_t is :\n',fit_t)
        return pos, fit_t

    def calculate_initial_y0(self):
        # calculate initial y0
        V1 = self.V1
        K1 = self.K1
        iroot = self.iroot
        TFLR_allscore = self.TFLR_allscore
        TFs_expr = self.TFs_expr
        # calculate initial y0
        x0 = TFLR_allscore[iroot,:,:]
        Y0 = TFs_expr[iroot,:]
        zero_y = torch.zeros(self.N_TFs, self.N_LRs).float().to(device)
        V1_ = torch.where(x0 > 0, V1, zero_y)  # torch.Size([10, 88, 63])
        K1_ = torch.where(x0 > 0, K1, zero_y)  # torch.Size([10, 88, 63])
        y0 = torch.sum((V1_ * x0) / ((K1_ + x0) + (1e-12)),dim=1) * Y0  # torch.Size([10, 88])
        return y0

    def hill_fun(self, y0, cell_i, t_i):  # trapezoidal rule approximation
        V1 = self.V1
        K1 = self.K1
        beta = self.beta
        TFLR_allscore = self.TFLR_allscore
        TFs_expr = self.TFs_expr
        x_i = TFLR_allscore[int(cell_i), :, :]
        Y_i = TFs_expr[int(cell_i), :]
        zero_y = torch.zeros(self.N_TFs, self.N_LRs)
        V1_ = torch.where(x_i > 0, V1, zero_y)  # torch.Size([88, 63])
        K1_ = torch.where(x_i > 0, K1, zero_y)  # torch.Size([88, 63])
        tmp1 = torch.sum((V1_ * x_i) / ((K1_ + x_i) + (1e-12)), dim=1) * Y_i
        tmp2 = tmp1 * torch.exp(beta*t_i)
        y_i = (((y0 + tmp2)*t_i)/2 + y0) * torch.exp(-beta*t_i)
        return y_i

    def solve_ym(self, fit_t):
        y0_ = self.calculate_initial_y0()
        N_cell_bacth = len(fit_t)
        N_TFs = self.N_TFs
        y_ode = torch.zeros((N_cell_bacth,N_TFs)).to(device)
        for i in range(N_cell_bacth):
            t_i = fit_t[i]
            if t_i.item() == 0:
                y_ode[i] = y0_
            else:
                y_ode[i] = self.hill_fun(y0_,i,t_i)
        return y_ode

    def net_f2(self, batch):
        TGs_expr, TFs_expr, TFLR_allscore= batch
        TGTF_regulate = self.regulate
        z_dnn, dz_dt = self.net_z()
        fit_t_pos, fit_t = self.assign_latenttime(TGs_expr)

        # Calculate ym
        y_ode = self.solve_ym(fit_t)
        zero_z = torch.zeros(self.N_TGs, self.N_TFs)
        V2_ = torch.where(TGTF_regulate == 1, self.V2, zero_z)
        K2_ = torch.where(TGTF_regulate == 1, self.K2, zero_z)
        tmp1 = V2_.unsqueeze(0) * y_ode.unsqueeze(1)
        tmp2 = (K2_.unsqueeze(0) + y_ode.unsqueeze(1)) + (1e-12)
        tmp3 = torch.sum(tmp1 / tmp2, dim=2)

        batch_size = TGs_expr.size(0)
        z_pred_exp = torch.zeros((batch_size, self.N_TGs)).to(device)
        dz_dt_pred = torch.zeros((batch_size, self.N_TGs)).to(device)
        for i in range(batch_size):
            z_pred_exp[i, :] = z_dnn[fit_t_pos[i]]
            dz_dt_pred[i, :] = dz_dt[fit_t_pos[i]]

        dz_dt_ode = tmp3 - z_pred_exp
        f = dz_dt_pred - dz_dt_ode

        return z_pred_exp, f

    def train(self, nIter):
        print('Training SpatialVelocity model with batch size:', self.batch_size)
        self.dnn.train()
        loss_adam = []
        iteration_adam = []
        a = 0

        for epoch in range(nIter):
            epoch_loss = 0
            for batch in self.dataloader:
                TGs_expr_batch, TFs_expr_batch, TFLR_allscore_batch = [x.to(device) for x in batch]

                z_pred, f_pred = self.net_f2(batch)
                loss1 = torch.mean((TGs_expr_batch - z_pred) ** 2)
                loss2 = torch.mean(f_pred ** 2)
                loss = 0.1 * loss1 + self.Lambda * loss2

                self.optimizer_Adam.zero_grad()
                loss.backward()
                self.optimizer_Adam.step()

                epoch_loss += loss.item()

            iteration_adam.append(a)
            loss_adam.append(epoch_loss / len(self.dataloader))
            a += 1

            if epoch % 100 == 0:
                print('loss1: %.3e, loss2: %.3e' % (loss1.item(), loss2.item()))
                print('Epoch [%d/%d], Loss: %.4f' % (epoch, nIter, epoch_loss / len(self.dataloader)))

        return iteration_adam, loss_adam

def get_raw_velo(adata, model):

    N_TGs = model.N_TGs
    # N_TFs = model.N_TFs
    N_cell = model.N_cell
    regulate = model.regulate
    TGs_expr = model.TGs_expr
    V1 = model.V1.detach()
    K1 = model.K1.detach()
    V2 = model.V2.detach()
    K2 = model.K2.detach()
    gamma = model.gamma.detach()
    fit_t = model.assign_latenttime(TGs_expr)[1]
    y_ode = model.solve_ym(fit_t)
    velo_raw = torch.zeros((N_cell, N_TGs)).to(device)
    for i in range(N_cell):
        y_i = y_ode[i,:]
        ym_ = regulate * y_i
        tmp1 = V2 * ym_
        tmp2 = (K2 + ym_) + (1e-12)
        tmp3 = torch.sum(tmp1 / tmp2, dim=1)
        dz_dt = tmp3 - gamma*TGs_expr[i, :]
        velo_raw[i,:] = dz_dt

    velo_norm = (velo_raw - velo_raw.min()) / (velo_raw.max() - velo_raw.min() + 1e-6)

    adata_copy = adata.copy()
    adata_copy.uns["velo_para"] = {}
    adata_copy.uns["velo_para"]['fit_V1'] = V1.detach().numpy()
    adata_copy.uns["velo_para"]['fit_K1'] = K1.detach().numpy()
    adata_copy.uns["velo_para"]['fit_V2'] = V2.detach().numpy()
    adata_copy.uns["velo_para"]['fit_K2'] = K2.detach().numpy()
    adata_copy.obs['fit_t'] = fit_t.detach()
    adata_copy.layers['velo_raw'] = velo_raw.detach().numpy()
    adata_copy.layers['velo_norm'] = velo_norm.detach().numpy()
    adata_copy.layers['velocity'] = adata_copy.layers['velo_raw']

    return adata_copy
